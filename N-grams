import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter, defaultdict
import random

#See "Data preprecosseing" to see the development of tokenz
drive.mount("/content/gdrive", force_remount=True)
dataset_path = '/content/gdrive/MyDrive/Speciale/answer_pre.pkl' #"full_copy" er den endelige fil, efer alt data merge er lavet
df = pd.read_pickle(dataset_path)

#Displaying N-grams for Mindhelper answers - source: https://github.com/gohjiayi/suicidal-text-detection/blob/main/eda.ipynb
def generate_ngrams(tokens, n):
    ngrams = zip(*[tokens[i:] for i in range(n)])
    return [" ".join(ngram) for ngram in ngrams]
tokenized_sent = df['tokens']

unigram = []
bigram = []
trigram = []
quadgram = []
for tokens in tokenized_sent:
    unigram.extend(generate_ngrams(tokens, 1))
    bigram.extend(generate_ngrams(tokens, 2))
    trigram.extend(generate_ngrams(tokens, 3))
    quadgram.extend(generate_ngrams(tokens, 4))

unigram_freq = Counter(unigram)
bigram_freq = Counter(bigram)
trigram_freq = Counter(trigram)
quadgram_freq = Counter(quadgram)
unigram_df = pd.DataFrame(unigram_freq.most_common(10), columns=['Unigram', 'Frequency'])
bigram_df = pd.DataFrame(bigram_freq.most_common(10), columns=['Bigram', 'Frequency'])
trigram_df = pd.DataFrame(trigram_freq.most_common(10), columns=['Trigram', 'Frequency'])
quadgram_df = pd.DataFrame(quadgram_freq.most_common(10), columns=['Quadgram', 'Frequency'])


def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,
                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',
                     bbox=[0, 0, 1, 1], header_columns=0,
                     ax=None, **kwargs):
    if ax is None:
        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])
        fig, ax = plt.subplots(figsize=size)
        ax.axis('off')

    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)
    mpl_table.auto_set_font_size(False)
    mpl_table.set_fontsize(font_size)
    for k, cell in  six.iteritems(mpl_table._cells):
        cell.set_edgecolor(edge_color)
        if k[0] == 0 or k[1] < header_columns:
            cell.set_text_props(weight='bold', color='w')
            cell.set_facecolor(header_color)
        else:
            cell.set_facecolor(row_colors[k[0] % len(row_colors)])
    return fig

fig1 = render_mpl_table(unigram_df, header_columns=0, col_width=3)
fig2 = render_mpl_table(bigram_df, header_columns=0, col_width=3)
fig3 = render_mpl_table(trigram_df, header_columns=0, col_width=3)
fig4 = render_mpl_table(quadgram_df, header_columns=0, col_width=3)
plt.show()


#Generating bigram sentences - https://towardsdatascience.com/text-generation-using-n-gram-model-8d12d9802aa0:
bigram_model = defaultdict(lambda: defaultdict(lambda: 0))
for bigram in bigram:
    w1, w2 = bigram.split()
    bigram_model[w1][w2] += 1

for w1 in bigram_model:
    total_count = float(sum(bigram_model[w1].values()))
    for w2 in bigram_model[w1]:
        bigram_model[w1][w2] /= total_count

def generate_sentence(bigram_model, seed_word, length=10):
    current_word = seed_word
    sentence = [current_word]
    for _ in range(length - 1):
        if current_word in bigram_model:
            next_word = random.choices(list(bigram_model[current_word].keys()),
                                       list(bigram_model[current_word].values()))[0]
            sentence.append(next_word)
            current_word = next_word
        else:
            break
    return ' '.join(sentence)

print(generate_sentence(bigram_model, 'selvmord', 20))
print(generate_sentence(bigram_model, 'angst', 20))
print(generate_sentence(bigram_model, 'skole', 20))
print(generate_sentence(bigram_model, 'forældre', 20))
print(generate_sentence(bigram_model, 'snakke', 20))


#Generating trigram sentences - https://towardsdatascience.com/text-generation-using-n-gram-model-8d12d9802aa0:
trigram_model = defaultdict(lambda: defaultdict(lambda: 0))
for trigram in trigram:
    w1, w2, w3 = trigram.split()
    trigram_model[(w1, w2)][w3] += 1

for w1_w2 in trigram_model:
    total_count = float(sum(trigram_model[w1_w2].values()))
    for w3 in trigram_model[w1_w2]:
        trigram_model[w1_w2][w3] /= total_count

def generate_sentence_trigram(trigram_model, seed_words, length=10):
    current_words = seed_words.split()
    if len(current_words) != 2:
        raise ValueError("Seed words must be a bigram")
    sentence = current_words
    for _ in range(length - 2):
        if tuple(current_words) in trigram_model:
            next_word = random.choices(list(trigram_model[tuple(current_words)].keys()),
                                       list(trigram_model[tuple(current_words)].values()))[0]
            sentence.append(next_word)
            current_words = sentence[-2:]
        else:
            break
    return ' '.join(sentence)
#Important to remeber that trigrams takes bigrams as input
print(generate_sentence_trigram(trigram_model, 'skrive herind', 20))
print(generate_sentence_trigram(trigram_model, 'din forældre', 20))
print(generate_sentence_trigram(trigram_model, 'kunne rigtig', 20))



#See "Data preprecosseing" to see the development of tokenz
drive.mount("/content/gdrive", force_remount=True)
dataset_path = "/content/gdrive/My Drive/Speciale/full_copy_m_dan_pre.pkl"
dan_df= pd.read_pickle(dataset_path)
print(dan_df)

#Displaying N-grams advice column messages - source: https://github.com/gohjiayi/suicidal-text-detection/blob/main/eda.ipynb
drive.mount("/content/gdrive", force_remount=True)
dataset_path = "/content/gdrive/My Drive/Speciale/full_copy_m_dan_pre.pkl"
dan_df= pd.read_pickle(dataset_path)
print(dan_df)
def generate_ngrams(tokens, n):
    ngrams = zip(*[tokens[i:] for i in range(n)])
    return [" ".join(ngram) for ngram in ngrams]
tokenized_sent = dan_df['tokens']

unigram = []
bigram = []
trigram = []
quadgram = []
for tokens in tokenized_sent:
    unigram.extend(generate_ngrams(tokens, 1))
    bigram.extend(generate_ngrams(tokens, 2))
    trigram.extend(generate_ngrams(tokens, 3))
    quadgram.extend(generate_ngrams(tokens, 4))

unigram_freq = Counter(unigram)
bigram_freq = Counter(bigram)
trigram_freq = Counter(trigram)
quadgram_freq = Counter(quadgram)
unigram_df = pd.DataFrame(unigram_freq.most_common(10), columns=['Unigram', 'Frequency'])
bigram_df = pd.DataFrame(bigram_freq.most_common(10), columns=['Bigram', 'Frequency'])
trigram_df = pd.DataFrame(trigram_freq.most_common(10), columns=['Trigram', 'Frequency'])
quadgram_df = pd.DataFrame(quadgram_freq.most_common(10), columns=['Quadgram', 'Frequency'])


def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,
                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',
                     bbox=[0, 0, 1, 1], header_columns=0,
                     ax=None, **kwargs):
    if ax is None:
        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])
        fig, ax = plt.subplots(figsize=size)
        ax.axis('off')

    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)
    mpl_table.auto_set_font_size(False)
    mpl_table.set_fontsize(font_size)
    for k, cell in  six.iteritems(mpl_table._cells):
        cell.set_edgecolor(edge_color)
        if k[0] == 0 or k[1] < header_columns:
            cell.set_text_props(weight='bold', color='w')
            cell.set_facecolor(header_color)
        else:
            cell.set_facecolor(row_colors[k[0] % len(row_colors)])
    return fig

fig1 = render_mpl_table(unigram_df, header_columns=0, col_width=3)
fig2 = render_mpl_table(bigram_df, header_columns=0, col_width=3)
fig3 = render_mpl_table(trigram_df, header_columns=0, col_width=3)
fig4 = render_mpl_table(quadgram_df, header_columns=0, col_width=3)
plt.show()



